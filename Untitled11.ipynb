{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54436c53-7c1c-42fd-9344-1b4c18d45d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 940.9ms\n",
      "Speed: 15.4ms preprocess, 940.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 683.7ms\n",
      "Speed: 5.6ms preprocess, 683.7ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 675.1ms\n",
      "Speed: 0.0ms preprocess, 675.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 659.6ms\n",
      "Speed: 0.0ms preprocess, 659.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 691.0ms\n",
      "Speed: 0.0ms preprocess, 691.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 674.9ms\n",
      "Speed: 0.0ms preprocess, 674.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 707.8ms\n",
      "Speed: 0.0ms preprocess, 707.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 756.6ms\n",
      "Speed: 0.0ms preprocess, 756.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 706.7ms\n",
      "Speed: 0.0ms preprocess, 706.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 691.0ms\n",
      "Speed: 0.0ms preprocess, 691.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 712.5ms\n",
      "Speed: 0.0ms preprocess, 712.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 655.0ms\n",
      "Speed: 2.1ms preprocess, 655.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 643.9ms\n",
      "Speed: 0.0ms preprocess, 643.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 643.1ms\n",
      "Speed: 0.0ms preprocess, 643.1ms inference, 15.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 687.1ms\n",
      "Speed: 0.0ms preprocess, 687.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 674.2ms\n",
      "Speed: 0.0ms preprocess, 674.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 643.3ms\n",
      "Speed: 0.0ms preprocess, 643.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 643.3ms\n",
      "Speed: 0.0ms preprocess, 643.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 643.7ms\n",
      "Speed: 0.0ms preprocess, 643.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 658.6ms\n",
      "Speed: 0.0ms preprocess, 658.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 643.2ms\n",
      "Speed: 0.0ms preprocess, 643.2ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 643.4ms\n",
      "Speed: 0.0ms preprocess, 643.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 659.1ms\n",
      "Speed: 0.0ms preprocess, 659.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 644.1ms\n",
      "Speed: 0.0ms preprocess, 644.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 658.5ms\n",
      "Speed: 0.0ms preprocess, 658.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 658.7ms\n",
      "Speed: 0.0ms preprocess, 658.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 653.0ms\n",
      "Speed: 0.0ms preprocess, 653.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 643.2ms\n",
      "Speed: 0.0ms preprocess, 643.2ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 659.0ms\n",
      "Speed: 0.0ms preprocess, 659.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 664.2ms\n",
      "Speed: 0.0ms preprocess, 664.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 658.8ms\n",
      "Speed: 0.0ms preprocess, 658.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 659.3ms\n",
      "Speed: 0.0ms preprocess, 659.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 660.3ms\n",
      "Speed: 0.0ms preprocess, 660.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 650.3ms\n",
      "Speed: 0.0ms preprocess, 650.3ms inference, 9.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 658.5ms\n",
      "Speed: 0.0ms preprocess, 658.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 643.9ms\n",
      "Speed: 0.0ms preprocess, 643.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 644.4ms\n",
      "Speed: 0.0ms preprocess, 644.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import cvzone\n",
    "import math\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from threading import Thread\n",
    "from ultralytics import YOLO\n",
    "\n",
    "class ObjectDetectionApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Object Detection GUI\")\n",
    "        self.root.configure(bg='black')  # Set background color to black\n",
    "\n",
    "        self.font = (\"Helvetica\", 12, \"bold\")  # Font style for buttons, change as needed\n",
    "        self.heading_font = (\"Helvetica\", 16, \"bold\")  # Font style for heading\n",
    "\n",
    "        self.heading_label = tk.Label(root, text=\"Object Detection Application\", bg='black', fg='orange', font=self.heading_font)\n",
    "        self.heading_label.pack(pady=20)\n",
    "\n",
    "        self.webcam_button = tk.Button(root, text=\"Use Webcam\", command=self.use_webcam, bg='orange', fg='black', font=self.font)\n",
    "        self.webcam_button.pack(pady=20)\n",
    "\n",
    "        self.video_button = tk.Button(root, text=\"Select Video File\", command=self.select_video, bg='orange', fg='black', font=self.font)\n",
    "        self.video_button.pack(pady=20)\n",
    "\n",
    "        self.cap = None\n",
    "        self.is_running = False\n",
    "        self.model = YOLO('yolov8l.pt')\n",
    "        self.classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "                           \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "                           \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\",\n",
    "                           \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\",\n",
    "                           \"kite\", \"pen\", \"skateboard\", \"surfboard\", \"tennis racket\",\n",
    "                           \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\",\n",
    "                           \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\",\n",
    "                           \"sofa\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"TV monitor\", \"laptop\", \"mouse\",\n",
    "                           \"remote\", \"keyboard\", \"cell phone\", \"toaster\", \"sink\", \"refrigerator\",\n",
    "                           \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair dryer\", \"pen\"]\n",
    "\n",
    "    def use_webcam(self):\n",
    "        if self.is_running:\n",
    "            self.stop_capture()\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        self.start_detection()\n",
    "\n",
    "    def select_video(self):\n",
    "        if self.is_running:\n",
    "            self.stop_capture()\n",
    "        video_path = filedialog.askopenfilename()\n",
    "        if video_path:\n",
    "            self.cap = cv2.VideoCapture(video_path)\n",
    "            self.start_detection()\n",
    "\n",
    "    def start_detection(self):\n",
    "        if not self.is_running:\n",
    "            self.is_running = True\n",
    "            Thread(target=self.detect_objects).start()\n",
    "\n",
    "    def stop_capture(self):\n",
    "        if self.cap is not None and self.cap.isOpened():\n",
    "            self.cap.release()\n",
    "        self.is_running = False\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    def detect_objects(self):\n",
    "        while self.cap.isOpened():\n",
    "            success, img = self.cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            results = self.model(img, stream=True)\n",
    "            for r in results:\n",
    "                boxes = r.boxes\n",
    "                for box in boxes:\n",
    "                    x1, y1, x2, y2 = box.xyxy[0]\n",
    "                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                    w, h = x2 - x1, y2 - y1\n",
    "                    cvzone.cornerRect(img, (x1, y1, w, h))\n",
    "                    conf = math.ceil(box.conf[0] * 100) / 100\n",
    "                    cls = int(box.cls[0])\n",
    "                    cvzone.putTextRect(img, f'{self.classNames[cls]} {conf}', (max(0, x1), max(35, y1)), scale=1, thickness=1)\n",
    "\n",
    "            cv2.imshow(\"Object Detection\", img)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        self.stop_capture()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = ObjectDetectionApp(root)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6dbd33-f54f-4bfe-9601-a21250b7fb08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
